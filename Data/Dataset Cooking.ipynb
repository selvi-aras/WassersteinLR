{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b57547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac6e931",
   "metadata": {},
   "source": [
    "#### Here we show how to prepare a UCI dataset\n",
    "To this end, we show an example dataset -- [`audiology`](https://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab47ec",
   "metadata": {},
   "source": [
    "Firstly, let us read the datasets (combine train:test datasets as we randomly split iteratively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29054c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (226, 71)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./audiology.data.csv\", header = None)\n",
    "df2 = pd.read_csv(\"./audiology.test.csv\", header = None)\n",
    "df = pd.concat([df, df2], axis= 0)\n",
    "del df2\n",
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fe214",
   "metadata": {},
   "source": [
    "Have a look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9049686d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>mild</td>\n",
       "      <td>f</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>?</td>\n",
       "      <td>t</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>normal</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>p1</td>\n",
       "      <td>cochlear_unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>?</td>\n",
       "      <td>t</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>normal</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>p2</td>\n",
       "      <td>cochlear_unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>mild</td>\n",
       "      <td>t</td>\n",
       "      <td>?</td>\n",
       "      <td>absent</td>\n",
       "      <td>mild</td>\n",
       "      <td>t</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>normal</td>\n",
       "      <td>t</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>p3</td>\n",
       "      <td>mixed_cochlear_age_fixation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0         1  2       3       4     5  6  7  8  9   ... 61 62      63 64  65  \\\n",
       "0  f      mild  f  normal  normal     ?  t  ?  f  f  ...  f  f  normal  t   a   \n",
       "1  f  moderate  f  normal  normal     ?  t  ?  f  f  ...  f  f  normal  t   a   \n",
       "2  t      mild  t       ?  absent  mild  t  ?  f  f  ...  f  f  normal  t  as   \n",
       "\n",
       "  66 67 68  69                           70  \n",
       "0  f  f  f  p1             cochlear_unknown  \n",
       "1  f  f  f  p2             cochlear_unknown  \n",
       "2  f  f  f  p3  mixed_cochlear_age_fixation  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36a06f",
   "metadata": {},
   "source": [
    "Manual work: column #69, as explained on the UCI webpage, is a unique row identifier. We must drop this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e41db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [69])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4b371",
   "metadata": {},
   "source": [
    "Rename columns as 1,2, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90db2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = np.arange(1,df.shape[1] + 1,1) #columns from 1 to 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640724f0",
   "metadata": {},
   "source": [
    "Check if the feature is multi-class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f285376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cochlear_age                        0.252212\n",
       "cochlear_unknown                    0.212389\n",
       "cochlear_age_and_noise              0.097345\n",
       "normal_ear                          0.097345\n",
       "cochlear_poss_noise                 0.088496\n",
       "mixed_cochlear_unk_fixation         0.039823\n",
       "possible_menieres                   0.035398\n",
       "conductive_fixation                 0.026549\n",
       "possible_brainstem_disorder         0.017699\n",
       "mixed_cochlear_age_otitis_media     0.017699\n",
       "otitis_media                        0.017699\n",
       "mixed_cochlear_unk_ser_om           0.013274\n",
       "mixed_cochlear_unk_discontinuity    0.008850\n",
       "mixed_cochlear_age_s_om             0.008850\n",
       "conductive_discontinuity            0.008850\n",
       "mixed_poss_noise_om                 0.008850\n",
       "cochlear_noise_and_heredity         0.008850\n",
       "retrocochlear_unknown               0.008850\n",
       "mixed_cochlear_age_fixation         0.008850\n",
       "bells_palsy                         0.004425\n",
       "poss_central                        0.004425\n",
       "mixed_poss_central_om               0.004425\n",
       "acoustic_neuroma                    0.004425\n",
       "cochlear_age_plus_poss_menieres     0.004425\n",
       "Name: 70, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_loc = df.shape[1]\n",
    "df[target_loc].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad91297",
   "metadata": {},
   "source": [
    "Binary encoding of majority class vs other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec58675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = df[target_loc].value_counts(normalize = True).head(1).index[0]\n",
    "df[target_loc] = (df[target_loc] == majority_class).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2787d",
   "metadata": {},
   "source": [
    "Now, notice that some features have two possible values, hence we do not need to one-hot encode them. For the others, we need to bring binary dummy variables (we do **not** drop the last dummies here, these are dealt with in the Julia code). Let us keep a list of the feature groups after a one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a6d3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features (and the label at the end) are encoded by the following variables\n",
      " 1-1,2-6,7-7,8-11,12-15,16-20,21-21,22-24,25-25,26-26,27-27,28-28,29-29,30-30,31-31,32-32,33-33,34-34,35-35,36-36,37-37,38-38,39-39,40-40,41-41,42-42,43-43,44-44,45-45,46-46,47-47,48-48,49-49,50-50,51-51,52-52,53-53,54-54,55-55,56-56,57-57,58-58,59-59,60-60,61-61,62-62,63-63,64-64,65-65,66-66,67-67,68-68,69-69,70-70,71-71,72-72,73-73,74-74,75-78,79-82,83-83,84-84,85-85,86-92,93-93,94-98,99-99,100-100,101-101,102-102\n"
     ]
    }
   ],
   "source": [
    "running_count = 0\n",
    "groups_string = \"\"\n",
    "for i in df.nunique(axis = 0):\n",
    "    if i >= 3:\n",
    "        groups_string = groups_string + str(running_count + 1) +\"-\"+str(running_count + i) +  \",\"\n",
    "        running_count = (running_count + i)\n",
    "    else:\n",
    "        groups_string = groups_string + str(running_count + 1)+\"-\"+str(running_count + 1) + \",\"\n",
    "        running_count = (running_count + 1)\n",
    "print(\"The features (and the label at the end) are encoded by the following variables\\n\",  groups_string[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd95f80",
   "metadata": {},
   "source": [
    "Save this file as a \"key\" as this will be used when referring to the original features. The name of the dataset is taaken as `audiologyBIN-cooked-key`, whose reason is the following\n",
    "- `audiology`: name of the UCI dataset\n",
    "- `BIN`: only added if the dataset has been binarified, that is, it was originally a multi-class feature dataset\n",
    "- `-cooked`: means we processed the data afterm downloading from the UCI repository\n",
    "- `-key`: is used for the files that specify the features -> one-hot dummies maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "359889da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"audiologyBIN-cooked-key.csv\", \"w\")\n",
    "n = text_file.write(groups_string[:-1])\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c85db9",
   "metadata": {},
   "source": [
    "Now we one-hot encode the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a63a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame() #empty dataframe\n",
    "for col in range(1,len(df.columns) + 1): #iterate over every column\n",
    "    if df[col].nunique() >= 3: #if there are more than 2 unique values\n",
    "        df_new = pd.concat([df_new, pd.get_dummies(data = df[col])], axis = 1) #standard one-hot encoding\n",
    "    else: #means the original feature has 2 unique values, then we keep it as it is, but convert it to 0/1 structure\n",
    "        df_new = pd.concat([df_new, pd.get_dummies(data = df[col], drop_first = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340af5f1",
   "metadata": {},
   "source": [
    "Rename columns, convert the dataframe elements to integer, and replace 0s with -1s to keep the $\\pm 1$ nature our paper has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34af61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns = np.arange(1, df_new.shape[1]+ 1, 1)\n",
    "df_new.astype(\"int\")\n",
    "df_new= df_new.replace([0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacf0e90",
   "metadata": {},
   "source": [
    "Check if everything went as planned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6345fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(np.abs(df_new) == 1)) == df_new.shape[0] * df_new.shape[1] #all ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c0e65",
   "metadata": {},
   "source": [
    "Now we can save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bb8588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('./audiology-cooked.csv', header=False, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
